def predict_image(img, mode):
"""GramAI Swasthya O Krushi Sahayak ‚Äì Northern Odisha AI Hackathon 2025
One app ‚Üí Paddy Disease + Skin Disease + Odia Voice

This file loads two MobilenetV3 models (paddy + skin), provides a
`predict_image()` function that accepts a PIL image (or uses a sample image)
and returns Odia text + an audio file produced with gTTS.
"""

import os
import io
import traceback
import numpy as np
from PIL import Image

import gradio as gr
import torch
from torchvision import transforms, models
from gtts import gTTS


SAMPLE_IMAGE_PATH = "sample_images/sample1.jpeg"
UPLOADED_IMAGE_FULLPATH = "/mnt/data/711BAC8A-1F53-43B6-983A-0B8A51C128D4.jpeg"

print("Loading models... (first run takes 2‚Äì3 mins; weights downloaded from URLs)")

# === Paddy Model ===
paddy_model = models.mobilenet_v3_small(pretrained=False)
try:
    paddy_model.classifier[3] = torch.nn.Linear(1024, 5)
except Exception:
    # fallback if classifier structure is different
    try:
        paddy_model.classifier = torch.nn.Sequential(torch.nn.Linear(1024, 5))
    except Exception:
        pass

try:
    paddy_model.load_state_dict(torch.hub.load_state_dict_from_url(
        "https://huggingface.co/spaces/fffiloni/paddy-disease-classification/resolve/main/paddy_model.pth",
        map_location="cpu"
    ))
except Exception:
    print("Warning: could not download paddy model weights; continuing without them")
paddy_model.eval()
paddy_classes = ["Bacterial Leaf Blight", "Brown Spot", "Leaf Blast", "Healthy", "Tungro"]

# === Skin Model ===
skin_model = models.mobilenet_v3_small(pretrained=False)
try:
    skin_model.classifier[3] = torch.nn.Linear(1024, 7)
except Exception:
    try:
        skin_model.classifier = torch.nn.Sequential(torch.nn.Linear(1024, 7))
    except Exception:
        pass

try:
    skin_model.load_state_dict(torch.hub.load_state_dict_from_url(
        "https://huggingface.co/spaces/ahmedshahriar/Skin_Disease/resolve/main/skin_model.pth",
        map_location="cpu"
    ))
except Exception:
    print("Warning: could not download skin model weights; continuing without them")
skin_model.eval()
skin_classes = ["Acne", "Eczema", "Psoriasis", "Ringworm (Dadru)", "Scabies", "Fungal Infection", "Healthy Skin"]

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# === Remedies in Odia ===
paddy_remedies = {
    "Bacterial Leaf Blight": "‡¨™‡¨æ‡¨≥‡¨ø‡¨§ ‡¨ï‡¨æ‡¨Æ: ‡¨Ü‡¨á‡¨Å‡¨ú‡¨ø‡¨ü‡¨ø‡¨ï ‡¨Ü‡¨¶‡¨æ‡¨®-‡¨™‡¨∞‡¨ø‡¨¨‡¨∞‡≠ç‡¨§‡≠ç‡¨§‡¨®; ‡¨Ü‡¨¨‡¨∂‡≠ç‡≠ü‡¨ï‡¨§‡¨æ‡¨®‡≠Å‡¨∏‡¨æ‡¨∞‡≠á ‡¨ï‡¨∞‡≠ç‡¨∑‡¨ï‡¨Æ‡¨æ‡¨®‡≠á ‡¨¨‡≠ç‡≠ü‡¨¨‡¨π‡¨æ‡¨∞ ‡¨ï‡¨∞‡¨ø‡¨¨‡≠á: ‡¨Æ‡¨æ‡¨®‡¨æ‡¨á‡¨Ø‡¨æ‡¨â‡¨•‡¨ø‡¨¨‡¨æ ‡¨¨‡≠ç‡≠ü‡¨æ‡¨ï‡≠ç‡¨ü‡≠á‡¨∞‡¨ø‡¨Ü ‡¨®‡¨ø‡¨¶‡¨æ‡¨®, ‡¨∏‡¨´‡¨æ‡¨á, ‡¨®‡¨ø‡≠ü‡¨Æ‡¨ø‡¨§ ‡¨™‡¨∞‡≠á‡¨ö‡¨æ‡¨∞‡¨ø‡¨§ ‡¨ï‡¨∞‡¨®‡≠ç‡¨§‡≠Å.",
    "Brown Spot": "‡¨∏‡≠Å‡¨ï‡≠ç‡¨∑‡≠ç‡¨Æ ‡¨∏‡¨´‡¨æ‡¨á, ‡¨Æ‡≠Å‡¨ñ‡≠ç‡≠ü‡¨§‡¨É ‡¨ì‡¨π‡≠ç‡¨≤‡¨æ‡¨á‡¨¨‡¨æ; ‡¨≤‡¨ï‡≠ç‡¨∑‡¨£ ‡¨π‡≠á‡¨≤‡≠á ‡¨´‡¨Ç‡¨ó‡¨∏ ‡¨®‡¨ø‡≠ü‡¨®‡≠ç‡¨§‡≠ç‡¨∞‡¨£ ‡¨î‡¨∑‡¨ß ‡¨¶‡¨ø‡¨Ö‡¨®‡≠ç‡¨§‡≠Å.",
    "Leaf Blast": "‡¨™‡≠ç‡¨∞‡¨≠‡¨æ‡¨¨‡¨ø‡¨§ ‡¨™‡¨§‡≠ç‡¨∞‡¨ï‡≠Å ‡¨π‡¨ü‡¨æ‡¨®‡≠ç‡¨§‡≠Å, ‡¨Ö‡¨®‡≠Å‡¨Æ‡¨§‡¨ø ‡¨™‡≠ç‡¨∞‡¨æ‡¨™‡≠ç‡¨§ ‡¨¨‡¨ø‡¨Æ‡≠ã‡¨ï‡≠ç‡¨∑ ‡¨´‡¨ô‡≠ç‡¨ó‡¨∏‡¨ø‡¨∏‡¨æ‡¨á‡¨°‡≠ç ‡¨≤‡¨æ‡¨ó‡¨æ‡¨®‡≠ç‡¨§‡≠Å.",
    "Healthy": "‡¨Ü‡¨™‡¨£‡¨ô‡≠ç‡¨ï ‡¨ß‡¨æ‡¨® ‡¨∏‡≠ç‡≠±‡¨∏‡≠ç‡¨• ‡¨Ö‡¨õ‡¨ø ‚Äî ‡¨Ö‡¨®‡≠Å‡¨∞‡¨ï‡≠ç‡¨∑‡¨£ ‡¨ú‡¨æ‡¨∞‡¨ø ‡¨∞‡¨ñ‡¨®‡≠ç‡¨§‡≠Å.",
    "Tungro": "‡¨≠‡≠á‡¨ï‡≠ç‡¨ü‡¨∞ ‡¨ï‡¨£‡≠ç‡¨ü‡≠ç‡¨∞‡≠ã‡¨≤‡≠ç (‡¨Æ‡≠ã‡¨∂‡¨æ) ‡¨ì ‡¨∞‡≠ã‡¨ó ‡¨™‡≠ç‡¨∞‡¨§‡¨ø‡¨∞‡≠ã‡¨ß‡¨ï ‡¨ï‡¨æ‡¨∞‡≠ç‡¨Ø‡≠ç‡≠ü; ‡¨•‡¨ø‡¨¨‡¨æ‡¨ï‡≠Å ‡¨ú‡¨∞‡≠Å‡¨∞‡≠Ä ‡¨π‡≠á‡¨≤‡≠á ‡¨¨‡¨ø‡¨∂‡≠á‡¨∑‡¨ú‡≠ç‡¨û ‡¨∏‡¨π‡¨æ‡≠ü‡¨§‡¨æ ‡¨®‡¨ø‡¨Ö‡¨®‡≠ç‡¨§‡≠Å."
}

skin_remedies = {
    "Acne": "‡¨Æ‡≠Å‡¨π‡¨Å ‡¨∏‡¨´‡¨æ‡¨á, ‡¨ì‡¨≠‡¨∞-‡¨á‡¨Ç‡¨´‡≠á‡¨ï‡¨∏‡¨® ‡¨® ‡¨π‡≠á‡¨¨‡¨æ ‡¨™‡¨æ‡¨á‡¨Å ‡¨°‡¨æ‡¨ï‡≠ç‡¨§‡¨∞‡¨ô‡≠ç‡¨ï ‡¨∏‡¨π ‡¨ü‡≠ç‡¨∞‡¨ø‡¨ü‡¨Æ‡≠á‡¨£‡≠ç‡¨ü.",
    "Eczema": "‡¨ö‡¨∞‡≠ç‡¨Æ‡¨ï‡≠Å ‡¨∂‡¨ø‡¨•‡¨ø‡¨≤‡¨æ ‡¨∞‡¨ñ‡¨®‡≠ç‡¨§‡≠Å, ‡¨Æ‡¨æ‡¨á‡¨∏‡≠ç‡¨ö‡¨∞‡¨æ‡¨á‡¨ú‡¨∞‡≠ç ‡¨¨‡≠ç‡≠ü‡¨¨‡¨π‡¨æ‡¨∞ ‡¨ï‡¨∞‡¨®‡≠ç‡¨§‡≠Å, ‡¨Ü‡¨¨‡¨∂‡≠ç‡≠ü‡¨ï ‡¨π‡≠á‡¨≤‡≠á ‡¨°‡¨æ‡¨ï‡≠ç‡¨§‡¨∞‡¨ô‡≠ç‡¨ï ‡¨∏‡¨π ‡¨∏‡¨≤‡¨æ‡¨π.",
    "Psoriasis": "‡¨°‡¨æ‡¨ï‡≠ç‡¨§‡¨∞ ‡¨∏‡¨π ‡¨¶‡≠á‡¨ñ‡¨æ ‡¨ï‡¨∞‡¨®‡≠ç‡¨§‡≠Å; ‡¨∏‡≠ç‡¨•‡¨æ‡¨®‡≠Ä‡≠ü ‡¨ï‡≠ç‡¨∞‡¨ø‡¨Æ‡≠ç ‡¨ì ‡¨ì‡¨∑‡¨ß ‡¨Ü‡¨¨‡¨∂‡≠ç‡≠ü‡¨ï.",
    "Ringworm (Dadru)": "‡¨´‡¨ô‡≠ç‡¨ó‡¨∏‡≠ç ‡¨∞‡≠ã‡¨ó ‚Äî ‡¨∏‡≠ç‡¨•‡¨æ‡¨®‡≠Ä‡≠ü ‡¨è‡¨£‡≠ç‡¨ü‡¨ø-‡¨´‡¨ô‡≠ç‡¨ó‡¨æ‡¨≤‡≠ç ‡¨ï‡≠ç‡¨∞‡¨ø‡¨Æ‡≠ç/‡¨≤‡≠ã‡¨∏‡¨®‡≠ç ‡¨≤‡¨æ‡¨ó‡¨æ‡¨®‡≠ç‡¨§‡≠Å; ‡¨∏‡¨´‡¨æ‡¨á ‡¨∞‡¨ñ‡¨®‡≠ç‡¨§‡≠Å.",
    "Scabies": "‡¨∏‡≠ç‡¨ï‡¨æ‡¨¨‡¨ø‡¨ú‡≠ç ‡¨π‡≠á‡¨≤‡≠á ‡¨°‡¨æ‡¨ï‡≠ç‡¨§‡¨∞‡¨ô‡≠ç‡¨ï ‡¨∏‡¨π ‡¨§‡¨¶‡¨®‡≠ç‡¨§; ‡¨®‡¨ø‡¨∞‡≠ç‡¨¶‡≠ç‡¨¶‡¨ø‡¨∑‡≠ç‡¨ü ‡¨Æ‡≠á‡¨°‡¨ø‡¨ï‡≠á‡¨∏‡¨®‡≠ç ‡¨¶‡¨∞‡¨ï‡¨æ‡¨∞.",
    "Fungal Infection": "‡¨´‡¨ô‡≠ç‡¨ó‡¨∏‡≠ç ‡¨®‡¨ø‡≠ü‡¨®‡≠ç‡¨§‡≠ç‡¨∞‡¨£ ‚Äî ‡¨≤‡≠ã‡¨ï‡¨æ‡¨≤‡≠ç ‡¨î‡¨∑‡¨ß/‡¨ï‡≠ç‡¨∞‡¨ø‡¨Æ‡≠ç; ‡¨∏‡¨´‡¨æ‡¨á ‡¨ì ‡¨∏‡≠Å‡¨ï‡≠ç‡¨∑‡≠ç‡¨Æ ‡¨∂‡¨∞‡≠Ä‡¨∞.",
    "Healthy Skin": "‡¨ö‡¨∞‡≠ç‡¨Æ ‡¨∏‡≠ç‡≠±‡¨∏‡≠ç‡¨• ‚Äî ‡¨∏‡≠Å‡¨∏‡≠ç‡¨• ‡¨Ü‡¨π‡¨æ‡¨∞ ‡¨ì ‡¨ñ‡≠Å‡¨¨ ‡¨ß‡¨≤‡¨æ ‡¨∏‡¨´‡¨æ‡¨á ‡¨∞‡¨ñ‡¨®‡≠ç‡¨§‡≠Å."
}


def predict_image(img, mode):
    """Predicts using either the paddy or skin model.

    - `img` can be a PIL.Image or a numpy array. If None, a bundled sample image is used.
    - `mode` is the radio label from the UI; detection chooses the model.

    Returns: (text_str, audio_file_path_or_None)
    """
    try:
        # If no image provided, try the sample or uploaded full path
        if img is None:
            if os.path.exists(SAMPLE_IMAGE_PATH):
                img = Image.open(SAMPLE_IMAGE_PATH).convert("RGB")
            elif os.path.exists(UPLOADED_IMAGE_FULLPATH):
                img = Image.open(UPLOADED_IMAGE_FULLPATH).convert("RGB")
            else:
                return "‡¨ï‡≠å‡¨£‡¨∏‡¨ø ‡¨õ‡¨¨‡¨ø ‡¨¶‡¨ø‡¨Ü‡¨Ø‡¨æ‡¨á‡¨®‡¨ø (No image provided)" , None

        if not isinstance(img, Image.Image):
            # convert numpy array to PIL
            img = Image.fromarray(np.asarray(img)).convert("RGB")

        input_tensor = transform(img).unsqueeze(0)

        if "Paddy" in mode or "‡¨ß‡¨æ‡¨®" in mode:
            model = paddy_model
            classes = paddy_classes
            remedies = paddy_remedies
        else:
            model = skin_model
            classes = skin_classes
            remedies = skin_remedies

        with torch.no_grad():
            outputs = model(input_tensor)
            # handle models that return logits or a tuple
            if isinstance(outputs, (list, tuple)):
                outputs = outputs[0]
            if outputs.dim() == 1:
                outputs = outputs.unsqueeze(0)
            probs = torch.softmax(outputs, dim=1).cpu().numpy()[0]
            top_idx = int(np.argmax(probs))
            label = classes[top_idx]
            confidence = float(probs[top_idx])

        remedy = remedies.get(label, "‡¨™‡¨∞‡¨æ‡¨Æ‡¨∞‡≠ç‡¨∂ ‡¨â‡¨™‡¨≤‡¨¨‡≠ç‡¨ß ‡¨®‡¨æ‡¨π‡¨ø‡¨Å")

        odia_text = f"‡¨ö‡¨ø‡¨π‡≠ç‡¨®‡¨ü: {label} ({confidence*100:.1f}%)\n‡¨™‡¨∞‡¨æ‡¨Æ‡¨∞‡≠ç‡¨∂: {remedy}"

        # Try to generate audio in Odia; fallback to Hindi/English
        audio_path = "result_odia.mp3"
        tts = None
        for lang in ("or", "hi", "en"):
            try:
                tts = gTTS(text=odia_text, lang=lang)
                tts.save(audio_path)
                break
            except Exception:
                tts = None

        if tts is None:
            # If tts failed, just return text and no audio
            return odia_text, None

        return odia_text, audio_path

    except Exception:
        traceback.print_exc()
        return "‡¨ï‡¨ø‡¨õ‡¨ø ‡¨§‡≠ç‡¨∞‡≠Å‡¨ü‡¨ø ‡¨ò‡¨ü‡¨ø‡¨õ‡¨ø (See server logs)", None


# === Gradio Interface ===
with gr.Blocks(title="GramAI") as demo:
    gr.Markdown("# üåæü©∫ GramAI ‚Äì ‡¨ó‡≠ç‡¨∞‡¨æ‡¨Æ‡¨è‡¨Ü‡¨á")
    gr.Markdown("### ‡¨ì‡¨°‡¨º‡¨ø‡¨Ü‡¨∞‡≠á ‡¨ß‡¨æ‡¨® + ‡¨ö‡¨∞‡≠ç‡¨Æ ‡¨∞‡≠ã‡¨ó ‡¨ö‡¨ø‡¨π‡≠ç‡¨®‡¨ü | Northern Odisha Hackathon 2025")
    mode = gr.Radio(["üåæ Paddy / ‡¨ß‡¨æ‡¨®", "ü©∫ Skin / ‡¨ö‡¨∞‡≠ç‡¨Æ"], label="‡¨¨‡¨æ‡¨õ‡¨®‡≠ç‡¨§‡≠Å | Choose:")
    img = gr.Image(type="pil", label="‡¨è‡¨ï ‡¨õ‡¨¨‡¨ø ‡¨Ö‡¨™‡¨≤‡≠ã‡¨°‡≠ç ‡¨ï‡¨∞‡¨®‡≠ç‡¨§‡≠Å | Upload an image")
    btn = gr.Button("üîç ‡¨¶‡≠á‡¨ñ‡¨®‡≠ç‡¨§‡≠Å | Analyze")
    out_text = gr.Textbox(label="‡¨â‡¨§‡≠ç‡¨§‡¨∞ | Result")
    out_audio = gr.Audio(label="‡¨ì‡¨°‡¨º‡¨ø‡¨Ü ‡¨ß‡≠ç‡≠±‡¨®‡¨ø | Listen")
    btn.click(predict_image, [img, mode], [out_text, out_audio])

if __name__ == "__main__":
    # ensure sample_images exists
    os.makedirs("sample_images", exist_ok=True)
    demo.launch(share=True)